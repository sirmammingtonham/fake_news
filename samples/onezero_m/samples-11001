======== SAMPLE 1 ========
Genio’s “[Mixed Reality](&lt;|url|&gt;)” service incorporates many of the same technologies, including those used by A.I. to synthesize facial expressions. Replicating facial expressions was a major research and development effort in the 1990s, and has been [amended](&lt;|url|&gt;) in recent years.

But there’s no telling how pervasive this facial recognition technology will be in our lives. By analyzing people’s faces, facial recognition technology could be used to identify them [as criminals](&lt;|url|&gt;). It could be used to screen people for bomb make-byes — or[/](<|url|>) for sure.

It’s not just facial recognition that threatens the privacy of people like Me. In [a deepfake video](&lt;|url|&gt;), obtained by a researcher at University of Cambridge, I see a person wearing a black turtleneck and dark shorts. The background is increasingly blended in with the foreground, and then edited out; it’s difficult to make out any words but “terrorist shit.” These shorts are fake, as is the turtleneck. The face is still there, but the words are nowhere to be found.

Under current deepfake technology, however, there’s no way to confirm that the fake part of a face is the real one. Deepfake researchers are [amazing](&lt;|url|&gt;) at creating believable avatars, and it’s no easy job turning images created in the real world into indistinguishable human voices. In a deepfake provided by a Beijing-based company called DeepDream, one of the company’s main software programs, researchers have created a program called [MKUltra](&lt;|url|&gt;) that can recognize brain activity and transform it into speech. They’ve also created a machine learning system that can decode spoken words and translate what it’s heard into sentences.

In other words, DeepDream and DeepDream’s other programs clearly and unambiguously violated [U.S. and Chinese law](&lt;|url|&gt;), which bars U.S. firms from using deepfake technologies for national security or commercial advantage.

At the same time, while the ability to use deepfake technologies in the United States may not be illegal, it is nonetheless a major embarrassment for a company like Amazon, whose employees and customers would almost certainly be ill-advised to use such technologies abroad.

How did DeepNude come to be used in the United States? The technology is deeply embedded in the internet ecosystem, which means that it reaches more people than ever before, and it has already caught on in new contexts beyond.

DeepNude was especially popular with the younger contingent of internet users in the college generation and those who found it congenial. Katy Manning, a senior at Texas Christian University who has studied deepfakes at Baylor University, says that at one point in her life, DeepNude was used in the form of an easy answer: “A lot of white guys used this because they were like, ‘No one does this!’” Seeing this, the rest of the college class decided to use it too.

This wasn’t just a one-off. According to research on the platform [by Stanford University](&lt;|url|&gt;) and the [Centre for Digital Media](&lt;|url|&gt;), the use of deepfakes increased after the first week of deepfakes became a thing of the past. From first week to last, the class had been using them religiously, and at the halfway mark, had created more than 200 deepfake videos.

This raises the question: how much is too much? A quick survey of the deepfakes that have been released over the years reveals a surprising answer: what seemed like an inconceivable idea just a few years ago has become reality in a matter of months.

The blooper reel consists of several dozen traditional deepfakes, many of which are shockingly similar to the celebrity selfies favored by the likes of Lindsay Lohan and Ariana Grande. The difference is that the popularized selfies — often with accompanying explanatory captions — are confined to a single device, and require the participation of virtually no one else.

In the past, studios or networks might have blinked and allowed their stars to walk away with purses they couldn’t cash, but Snapchat wants to be different. It can’t allow its platform to be a repository for all the selfies of today’s pop stars, because the public good outweighs the short-term PR gains of a few seconds of fame. So it has implemented a new policy: no filters
