======== SAMPLE 1 ========

Tandon argues that the U.S. should be taking a page from Japan’s playbook of trying to fix the stagnation of income inequality that has been a hallmark of the post-war growth model. “Technological innovation speeds upward inequality,” Tandon says. “This makes sense if you consider that productivity is the best long-term growth engine.”

But Fujimoto, now 70, feels that talk is too fast. He isn’t sure that talk is the right place. “It might encourage people to have unrealistic expectations, which has a negative impact on growth,” he says.

What the government can do, he says, is give authors a warning before they make any money. “If they have any intention of using the technology for generating income, they should be explicit about that before they go into the rest of the paper,” Fujimoto says.

The authors say they will contest any and all claims made in the study.

Fujimoto’s advice is spot-on. “I think this is very serious,” says Lee, who adds that Nobel Prize-winning economists such as [Arnon Milne](&lt;|url|&gt;) have warned about the dangers of technology predictability. “They need to be challenged on their assumptions and without being challenged on their assumptions, they tend to go on autopilot.”

But let’s say for a moment that Fujimoto’s warning isn’t based on solid economic theory. What’s the catch? It’s hard to know what, exactly, economic theory says about a given technology, especially given that the field of economics is populated by people who don’t work for Silicon Valley companies.

David Autor, a professor of economics at Boston University who was not involved with the study, says that while “a lot of papers don’t show strong evidence” that Silicon Valley companies are a waste dump, they certainly don’t need to be a waste dump, either. “The reality is that Silicon Valley companies are very interested in being socially responsible, and they have enormous interests in the community,” he says. “So there’s a question of whether this is really the kind of environment that we want to be working in or not.”

Autor points out that the study doesn’t offer any real solutions to the real problems facing the world. “We aren’t developing new tech solutions to the problems that we’ve created,” he says. “We are attempting to imagine new ways of looking at the problems and solutions.”

The authors of the paper actually spend a good deal of time developing an argument for why mechanization is bad for workers, arguing that technological development tends to [drive workers to] a place where they will do the work that’s easier, more comfortably, and at the same time they will be seen as commodities, something to be bought and sold. This is an argument that the paper does in fact make, but it is nowhere near as compelling as we thought.

The author next writes:
> There is a danger, almost without realizing it, that workers will lose sight of the fact that they are struggling for survival, and that’s a problem if you don’t adjust for it.

This might be true, but we still don’t need a Nobel to see that automation is often not just a technical problem, but a psychological one. In other words, automation isn’t neutral and we shouldn’t expect other things to change without our attention.

Until we have a more precise and profound analysis of why some jobs became obsolete, as opposed to why others grew, there’s no guarantee of what jobs will be created in the future. Moreover, given that AI will become more powerful and more ubiquitous with each passing year, the sorts of questions that require thinking beyond the comfort of our computers won’t seem like a viable part of the conversation.

Perhaps the solution lies in Facebook taking a page from its charitable spirit. After all, a platform like Life is good for, well, making friends, is good for, well, making friends. And bots are kind of the opposite of that. Whereas a human can find someone kindred spirit on a Facebook feed, a bot can find you.

Facebook has already begun to implement measures to curb harassment, including through the creation of a [shadow banning](&lt;|url|&gt;) function that, among other things, removes users’ access to the site should they violate the platform’s rules. But there’s no telling how these tools will affect the core of the platform, if anything.

“I think the moderation is reactive,” says Frey
